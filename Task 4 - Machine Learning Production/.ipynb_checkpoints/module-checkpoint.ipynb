{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0933e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTING PACKAGES\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a93c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DEFINE GLOBAL CONSTANTS\n",
    "SALE_PATH = \"sales.csv\"\n",
    "STOCK_PATH = \"sensor_stock_levels.csv\"\n",
    "TEMP_PATH = \"sensor_storage_temperature.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e109044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ALGORITHM CODE\n",
    "\n",
    "# Load Data\n",
    "def data_loading(path):\n",
    "    '''\n",
    "    This function takes a path string to a CSV file and loads it into a Pandas DataFrame\n",
    "    \n",
    "    :param  path(optional):str, relative path of the CSV file\n",
    "    \n",
    "    :return df: pd.DataFrame\n",
    "    '''\n",
    "    df = pd.read_csv(path)\n",
    "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff4b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time to standard datetime\n",
    "def convert_to_datetime(data: pd.DataFrame = None, column: str = None):\n",
    "    datetime_converted_df = data.copy()\n",
    "    datetime_converted_df[column] = pd.to_datetime(datetime_converted_df[column], format='%Y-%m-%d %H:%M:%S')\n",
    "    return datetime_converted_df\n",
    "\n",
    "def convert_timestamp_to_hourly(data: pd.DataFrame = None, column: str = None):\n",
    "    hourly_converted_df = data.copy()\n",
    "    new_ts = hourly_converted_df[column].tolist()\n",
    "    new_ts = [i.strftime('%Y-%m-%d %H:00:00') for i in new_ts]\n",
    "    new_ts = [datetime.strptime(i, '%Y-%m-%d %H:00:00') for i in new_ts]\n",
    "    hourly_converted_df[column] = new_ts\n",
    "    return hourly_converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a64ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable and predictor variables\n",
    "\n",
    "def create_X_y(data: pd.DataFrame = None, column: str = None):\n",
    "    '''\n",
    "    This function takes in a Pandas DataFrame and splits the columns into a target column and a set of predictor variables,\n",
    "    i.e. X & y. These two splits of the data will be used to train a supervised machine learning model.\n",
    "    \n",
    "    :param  data: pd.DataFrame, dataframe containing data for the model\n",
    "    :param  target: str, target variable that you want to predict\n",
    "    \n",
    "    :return X: pd.DataFrame, y: pd.Series\n",
    "    '''\n",
    "    X = data.drop(columns = [column])\n",
    "    y = data[column]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c76943a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train algorithm\n",
    "def train_algorithm_with_cross_validation(X : pd.DataFrame = None, y : pd.Series = None, K = 10, split = 0.75):\n",
    "    '''\n",
    "    This function takes the predictor and target variables and trains a Random Forest Regressor model accros K folds.\n",
    "    Standard Scaler will also be applied. Using cross-validation, performance metrics (mean_absolute_error) \n",
    "    will be output for each fold during training\n",
    "    \n",
    "    :param      X: pd.DataFrame, predictor variables\n",
    "    :param      y: pd.Series, target variable\n",
    "\n",
    "    :return\n",
    "    '''\n",
    "    accuracy = [] # Create a list that will store the accuracies of each fold\n",
    "    \n",
    "    for fold in range(0, K): # Enter a loop to run K folds of cross-validation\n",
    "\n",
    "        # Instantiate algorithm\n",
    "        model = RandomForestRegressor()\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Create training and test samples\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=split, random_state=42)\n",
    "\n",
    "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
    "        # and helps the algorithm to not be greedy with large values\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Train model\n",
    "        trained_model = model.fit(X_train, y_train)\n",
    "\n",
    "        # Generate predictions on test sample\n",
    "        y_pred = trained_model.predict(X_test)\n",
    "\n",
    "        # Compute accuracy, using mean absolute error\n",
    "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
    "        accuracy.append(mae)\n",
    "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
    "        \n",
    "    # Finish by computing the average MAE across all folds\n",
    "    print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5b16c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. MAIN FUNCTION\n",
    "def model_execute():\n",
    "    '''\n",
    "    This function executes the training pipeline of loading the prepared dataset from a CSV file,\n",
    "    split the dataset, then training the machine learning model\n",
    "    \n",
    "    :param\n",
    "    \n",
    "    :return\n",
    "    '''\n",
    "    # Load the data\n",
    "    df = data_loading() # Data pre-processing, feature engineering first, merge all the data into new CSV file, then use this function\n",
    "    \n",
    "    # Split the data into into predictors and target variables\n",
    "    X, y = create_X_y(data = df)\n",
    "    \n",
    "    # Train the ML model\n",
    "    train_algorithm_with_cross_validation(X, y, K, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15741a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
